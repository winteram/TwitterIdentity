{
 "metadata": {
  "name": "",
  "signature": "sha256:b0218b953b217b27f1183f7ac1be00e59910264aaf34749019c7014ee8b3e879"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys, os\n",
      "import pandas as pd\n",
      "import cPickle as pickle\n",
      "import re\n",
      "import numpy as np\n",
      "%matplotlib "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: Qt4Agg\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.chdir('C:/Users/Asaf/Documents/GitHub/TwitterIdentity/src/py')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from encrypt import decode_salt\n",
      "\n",
      "from vaderSentiment import sentiment as vaderSentiment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "survey=pd.read_pickle('DataFrames/SurveySentiment')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k=list(survey.keys())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This represents all twitter files\n",
      "#Just realized I can both Twitter and Facebook in this file, because the code is going to be very similary\n",
      "#So, I could have for instance, path_fb, and path_tw, \n",
      "\n",
      "#I would have to run separate loops since they work on separate files, but since the mechanics are\n",
      "#the same I might as well just run them here. \n",
      "\n",
      "all_files_tw=[]\n",
      "all_files_fb=[]\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path= 'B:/Participants/'\n",
      "path2='B:/Twitter_Part/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#For Facebook files, make sure the file exists. If it does, then add the directory name into the list\n",
      "\n",
      "\n",
      "for i in survey['FBid']:\n",
      "    path_full=path+i+'/status_sentiment'\n",
      "    \n",
      "    if os.path.exists(path_full):\n",
      "        all_files_fb.append(path_full)\n",
      "\n",
      "for i in survey['Twitid']:\n",
      "    path_full=path2+i+'/vader_sent'\n",
      "    if os.path.exists(path_full):\n",
      "        all_files_tw.append(path_full)\n",
      "\n",
      "        \n",
      "''' \n",
      "   try:\n",
      "        z=pickle.load( open(path_full, \"rb\" ))\n",
      "        good_files.append(path_full)\n",
      "    except:\n",
      "        bad_files.append()\n",
      " '''\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "' \\n   try:\\n        z=pickle.load( open(path_full, \"rb\" ))\\n        good_files.append(path_full)\\n    except:\\n        bad_files.append()\\n '"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(all_files_fb)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "570"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_files[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "'B:/Participants/100000967142850/statuses'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "k=re.findall(r'\\d+',all_files[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "['100000967142850']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "z=[1,2,3,4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "np.percentile(z,25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "1.75"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.std(z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "1.1180339887498949"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "'''\n",
      "\n",
      "#initiate columns in survey\n",
      "\n",
      "#medians facebook\n",
      "survey['fb_vader_pos_mdn']=None\n",
      "survey['fb_vader_neg_mdn']=None\n",
      "survey['fb_vad_neu_mdn']=None\n",
      "survey['fb_vad_comp_mdn']=None\n",
      "\n",
      "#medians twitter\n",
      "\n",
      "survey['tw_vader_pos_mdn']=None\n",
      "survey['tw_vader_neg_mdn']=None\n",
      "survey['tw_vad_neu_mdn']=None\n",
      "survey['tw_vad_comp_mdn']=None\n",
      "\n",
      "#sds twitter\n",
      "\n",
      "survey['tw_vader_pos_sd']=None\n",
      "survey['tw_vader_neg_sd']=None\n",
      "survey['tw_vad_neu_sd']=None\n",
      "survey['tw_vad_comp_sd']=None\n",
      "\n",
      "#sds facebook\n",
      "\n",
      "survey['fb_vader_pos_sd']=None\n",
      "survey['fb_vader_neg_sd']=None\n",
      "survey['fb_vad_neu_sd']=None\n",
      "survey['fb_vad_comp_sd']=None\n",
      "\n",
      "#Bottom quartile facebook\n",
      "\n",
      "survey['fb_vader_pos25']=None\n",
      "survey['fb_vader_neg25']=None\n",
      "survey['fb_vad_neu25']=None\n",
      "survey['fb_vad_comp25']=None\n",
      "\n",
      "#Top quartile facebook\n",
      "\n",
      "survey['fb_vader_pos75']=None\n",
      "survey['fb_vader_neg75']=None\n",
      "survey['fb_vad_neu75']=None\n",
      "survey['fb_vad_comp75']=None\n",
      "\n",
      "#Bottom quartile Twitter\n",
      "\n",
      "survey['tw_vader_pos25']=None\n",
      "survey['tw_vader_neg25']=None\n",
      "survey['tw_vad_neu25']=None\n",
      "survey['tw_vad_comp25']=None\n",
      "\n",
      "#Top quartile Twitter\n",
      "\n",
      "survey['tw_vader_pos75']=None\n",
      "survey['tw_vader_neg75']=None\n",
      "survey['tw_vad_neu75']=None\n",
      "survey['tw_vad_comp75']=None\n",
      "\n",
      "#FB number of statuses\n",
      "\n",
      "survey['status_num']=None\n",
      "\n",
      "#TW number of statuses\n",
      "\n",
      "survey['tweet_num']=None  \n",
      "\n",
      "\n",
      "\n",
      "'''\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in all_files[0:1]:\n",
      "        z=pickle.load(open(i))\n",
      "        status_sent=[]\n",
      "        temp=re.findall(r'\\d+',i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "['659724965']"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "\n",
      "#Here is where the real sentiment analysis begins.\n",
      "for file_name in all_files_tw:\n",
      "    \n",
      "\n",
      "\n",
      "    status_sent=pickle.load(open(file_name))\n",
      "    # I took out the bit about opening as a binary, it doesn't work some files, and it screws up the the indexing\n",
      "    #basically it adds an /r to the end of keys, which makes it more cumbersome. \n",
      "    #Now we want to pull out the all out each status for each person, and then look at the stentiment for that status.\n",
      "    #We also want to store the sentiments for each person in another pickle file. This way later we can look at distributions and stuff\n",
      "    #for each person initilize a new list that will be the sentiment for all their status\n",
      "\n",
      "    temp=re.findall(r'\\d+',file_name)\n",
      "    \n",
      "    status_len=len(status_sent)\n",
      "    survey.tweet_num[survey.Twitid==temp[0]]=status_len\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    #pickle.dump( status_sent, open( sent_path, \"wb\" ) )               \n",
      "    pos=np.median([i['pos'] for i in status_sent])\n",
      "    neg=np.median([i['neg'] for i in status_sent])\n",
      "    neu=np.median([i['neu'] for i in status_sent])\n",
      "    compound=np.median([i['compound'] for i in status_sent])\n",
      "    survey.tw_vader_pos_mdn[survey.Twitid==temp[0]]=pos\n",
      "    survey.tw_vader_neg_mdn[survey.Twitid==temp[0]]=neg\n",
      "    survey.tw_vad_neu_mdn[survey.Twitid==temp[0]]=neu\n",
      "    survey.tw_vad_comp_mdn[survey.Twitid==temp[0]]=compound\n",
      "    \n",
      "                   \n",
      "    pos=np.std([i['pos'] for i in status_sent])\n",
      "    neg=np.std([i['neg'] for i in status_sent])\n",
      "    neu=np.std([i['neu'] for i in status_sent])\n",
      "    compound=np.std([i['compound'] for i in status_sent])\n",
      "    survey.tw_vader_pos_sd[survey.Twitid==temp[0]]=pos\n",
      "    survey.tw_vader_neg_sd[survey.Twitid==temp[0]]=neg\n",
      "    survey.tw_vad_neu_sd[survey.Twitid==temp[0]]=neu\n",
      "    survey.tw_vad_comp_sd[survey.Twitid==temp[0]]=compound\n",
      "    \n",
      "    pos=np.percentile([i['pos'] for i in status_sent],25)\n",
      "    neg=np.percentile([i['neg'] for i in status_sent],25)\n",
      "    neu=np.percentile([i['neu'] for i in status_sent],25)\n",
      "    compound=np.percentile([i['compound'] for i in status_sent],25)\n",
      "    survey.tw_vader_pos25[survey.Twitid==temp[0]]=pos\n",
      "    survey.tw_vader_neg25[survey.Twitid==temp[0]]=neg\n",
      "    survey.tw_vad_neu25[survey.Twitid==temp[0]]=neu\n",
      "    survey.tw_vad_comp25[survey.Twitid==temp[0]]=compound\n",
      "    \n",
      "    \n",
      "    pos=np.percentile([i['pos'] for i in status_sent],75)\n",
      "    neg=np.percentile([i['neg'] for i in status_sent],75)\n",
      "    neu=np.percentile([i['neu'] for i in status_sent],75)\n",
      "    compound=np.percentile([i['compound'] for i in status_sent],75)\n",
      "    survey.tw_vader_pos75[survey.Twitid==temp[0]]=pos\n",
      "    survey.tw_vader_neg75[survey.Twitid==temp[0]]=neg\n",
      "    survey.tw_vad_neu75[survey.Twitid==temp[0]]=neu\n",
      "    survey.tw_vad_comp75[survey.Twitid==temp[0]]=compound\n",
      "    \n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#initiate columns in survey\n",
      "\n",
      "#medians facebook\n",
      "survey['fb_vader_pos']=None\n",
      "survey['fb_vader_neg']=None\n",
      "survey['fb_vad_neu']=None\n",
      "survey['fb_vad_comp']=None\n",
      "error_log={}\n",
      "for file_name in all_files_fb:\n",
      "    \n",
      "\n",
      "\n",
      "    status_sent=pickle.load(open(file_name))\n",
      "    # I took out the bit about opening as a binary, it doesn't work some files, and it screws up the the indexing\n",
      "    #basically it adds an /r to the end of keys, which makes it more cumbersome. \n",
      "    #Now we want to pull out the all out each status for each person, and then look at the stentiment for that status.\n",
      "    #We also want to store the sentiments for each person in another pickle file. This way later we can look at distributions and stuff\n",
      "    #for each person initilize a new list that will be the sentiment for all their status\n",
      "\n",
      "    temp=re.findall(r'\\d+',file_name)\n",
      "    \n",
      "    status_len=len(status_sent)\n",
      "    survey.status_num[survey.FBid==temp[0]]=status_len\n",
      "    \n",
      "    \n",
      "    try:\n",
      "        \n",
      "        pos=np.mean([i['pos'] for i in status_sent])\n",
      "        neg=np.mean([i['neg'] for i in status_sent])\n",
      "        neu=np.mean([i['neu'] for i in status_sent])\n",
      "        compound=np.mean([i['compound'] for i in status_sent])\n",
      "        survey.fb_vader_pos[survey.FBid==temp[0]]=pos\n",
      "        survey.fb_vader_neg[survey.FBid==temp[0]]=neg\n",
      "        survey.fb_vad_neu[survey.FBid==temp[0]]=neu\n",
      "        survey.fb_vad_comp[survey.FBid==temp[0]]=compound\n",
      "        \n",
      "         #pickle.dump( status_sent, open( sent_path, \"wb\" ) )               \n",
      "        pos=np.median([i['pos'] for i in status_sent])\n",
      "        neg=np.median([i['neg'] for i in status_sent])\n",
      "        neu=np.median([i['neu'] for i in status_sent])\n",
      "        compound=np.median([i['compound'] for i in status_sent])\n",
      "        survey.fb_vader_pos_mdn[survey.FBid==temp[0]]=pos\n",
      "        survey.fb_vader_neg_mdn[survey.FBid==temp[0]]=neg\n",
      "        survey.fb_vad_neu_mdn[survey.FBid==temp[0]]=neu\n",
      "        survey.fb_vad_comp_mdn[survey.FBid==temp[0]]=compound\n",
      "\n",
      "\n",
      "        pos=np.std([i['pos'] for i in status_sent])\n",
      "        neg=np.std([i['neg'] for i in status_sent])\n",
      "        neu=np.std([i['neu'] for i in status_sent])\n",
      "        compound=np.std([i['compound'] for i in status_sent])\n",
      "        survey.fb_vader_pos_sd[survey.FBid==temp[0]]=pos\n",
      "        survey.fb_vader_neg_sd[survey.FBid==temp[0]]=neg\n",
      "        survey.fb_vad_neu_sd[survey.FBid==temp[0]]=neu\n",
      "        survey.fb_vad_comp_sd[survey.FBid==temp[0]]=compound\n",
      "\n",
      "        pos=np.percentile([i['pos'] for i in status_sent],25)\n",
      "        neg=np.percentile([i['neg'] for i in status_sent],25)\n",
      "        neu=np.percentile([i['neu'] for i in status_sent],25)\n",
      "        compound=np.percentile([i['compound'] for i in status_sent],25)\n",
      "        survey.fb_vader_pos25[survey.FBid==temp[0]]=pos\n",
      "        survey.fb_vader_neg25[survey.FBid==temp[0]]=neg\n",
      "        survey.fb_vad_neu25[survey.FBid==temp[0]]=neu\n",
      "        survey.fb_vad_comp25[survey.FBid==temp[0]]=compound\n",
      "\n",
      "\n",
      "        pos=np.percentile([i['pos'] for i in status_sent],75)\n",
      "        neg=np.percentile([i['neg'] for i in status_sent],75)\n",
      "        neu=np.percentile([i['neu'] for i in status_sent],75)\n",
      "        compound=np.percentile([i['compound'] for i in status_sent],75)\n",
      "        survey.fb_vader_pos75[survey.FBid==temp[0]]=pos\n",
      "        survey.fb_vader_neg75[survey.FBid==temp[0]]=neg\n",
      "        survey.fb_vad_neu75[survey.FBid==temp[0]]=neu\n",
      "        survey.fb_vad_comp75[survey.FBid==temp[0]]=compound\n",
      "        \n",
      "       \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        \n",
      "\n",
      "    except Exception as e:\n",
      "        error_log[temp[0]]=e\n",
      "        \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "survey.fb_vader_pos_mdn\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "0         0\n",
        "1     0.093\n",
        "2         0\n",
        "3     0.296\n",
        "4     0.134\n",
        "5      None\n",
        "6     0.168\n",
        "7         0\n",
        "8      None\n",
        "9     0.272\n",
        "10        0\n",
        "11        0\n",
        "12     None\n",
        "13     None\n",
        "14        0\n",
        "...\n",
        "800      None\n",
        "801      None\n",
        "802      None\n",
        "803      None\n",
        "804     0.256\n",
        "805      None\n",
        "806     0.117\n",
        "807      None\n",
        "808         0\n",
        "809         0\n",
        "810      None\n",
        "811    0.3155\n",
        "812     0.139\n",
        "813      None\n",
        "814     0.377\n",
        "Name: fb_vader_pos_mdn, Length: 815, dtype: object"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "survey.Twitid[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "'278764901'"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k='B:/Participants/100002522111681/status_sentiment'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g=pickle.load(open(k, 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.median([])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "nan"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "error_log=[]\n",
      "all_statuses=[]\n",
      "\n",
      "#Here is where the real sentiment analysis begins.\n",
      "for file_name in all_files[0:1]:\n",
      "    try:\n",
      "        z=pickle.load(open(i))\n",
      "        # I took out the bit about opening as a binary, it doesn't work some files, and it screws up the the indexing\n",
      "        #basically it adds an /r to the end of keys, which makes it more cumbersome. \n",
      "        #Now we want to pull out the all out each status for each person, and then look at the stentiment for that status.\n",
      "        #We also want to store the sentiments for each person in another pickle file. This way later we can look at distributions and stuff\n",
      "        #for each person initilize a new list that will be the sentiment for all their status\n",
      "        status_sent=[]\n",
      "        temp=re.findall(r'\\d+',i)\n",
      "        sent_path='B:/Participants/'+temp[0]+'/status_sentiment'\n",
      "       \n",
      "        for status_set in z:\n",
      "            for status_list in status_set['data']:\n",
      "                if 'message' in status_list.keys():\n",
      "                    for message in status_list['message']:\n",
      "                        msg=message.encode('utf-8')\n",
      "                        sent = vaderSentiment(msg)\n",
      "                        status_sent.append(sent)\n",
      "                        all_statuses.append(sent)\n",
      "                        pickle.dump( status_sent, open( sent_path, \"wb\" ) )\n",
      "        #The other piece of all this that I need to put the mean sentiments for each each category into the survey data frame\n",
      "        #We're just talking about means.\n",
      "        pos=np.mean([i['pos'] for i in status_sent])\n",
      "        neg=np.mean([i['neg'] for i in status_sent])\n",
      "        neu=np.mean([i['neu'] for i in status_sent])\n",
      "        comp=np.mean([i['composite'] for i in status_sent])\n",
      "        compound=np.mean([i['compound'] for i in status_sent])\n",
      "        survey.fb_vader_pos[survey.FBid==temp[0]]=pos\n",
      "        survey.fb_vader_neg[survey.FBid==temp[0]]=neg\n",
      "        survey.fb_vad_neutral[survey.FBid==temp[0]]=neu\n",
      "        survey.fb_vad_comp[survey.FBid==temp[0]]=comp\n",
      "        \n",
      "            \n",
      "            \n",
      "        \n",
      "    except Exception, e:\n",
      "        error_log.append(file_name)\n",
      "        print e"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "survey.fb_vader_pos.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x12b85e10>"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "survey.fb_vader_neg.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x134e6320>"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "survey.fb_vad_comp.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x127090f0>"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "survey.fb_vad_neutral.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x12ef6278>"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(survey,open('DataFrames/SurveySentiment', 'wb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "survey.keys()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "Index([u'Agree', u'FBid', u'IUname', u'Id', u'Referred_by', u'Twitid', u'active', u'afraid', u'alert', u'ashamed', u'attentive', u'comments', u'con_agree_0', u'con_agree_1', u'con_agree_10', u'con_agree_11', u'con_agree_12', u'con_agree_13', u'con_agree_14', u'con_agree_15', u'con_agree_16', u'con_agree_17', u'con_agree_18', u'con_agree_19', u'con_agree_2', u'con_agree_20', u'con_agree_21', u'con_agree_22', u'con_agree_23', u'con_agree_24', u'con_agree_25', u'con_agree_26', u'con_agree_27', u'con_agree_28', u'con_agree_29', u'con_agree_3', u'con_agree_30', u'con_agree_31', u'con_agree_32', u'con_agree_33', u'con_agree_34', u'con_agree_4', u'con_agree_5', u'con_agree_6', u'con_agree_7', u'con_agree_8', u'con_agree_9', u'determined', u'distressed', u'edu', u'ended', u'enthusiastic', u'ethnicity', u'excited', u'fam_income', u'fb_academic', u'fb_academic_comments', u'fb_appearance', u'fb_appearance_comments', u'fb_comments', u'fb_doing', u'fb_doing_comments', u'fb_entertain', u'fb_entertain_comments', u'fb_family', u'fb_family_comments', u'fb_feel', u'fb_feel_comments', u'fb_god', u'fb_god_comments', u'fb_political', u'fb_political_comments', u'fb_where', u'fb_where_comments', u'gender', u'guilty', u'hostile', u'income', u'inspired', u'interested', u'irritable', u'jittery', u'nervous', u'own_URL1', u'own_URL2', u'own_URL3', u'own_form11', u'own_form12', u'own_form21', u'own_form22', u'own_form31', u'own_form32', u'party', u'party0_bond', u'party10_common_avg', u'party11_similar_avg', u'party12_common_oth', u'party13_similar_oth', u'party1_solidarity', u'party2_committed', ...], dtype='object')"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(all_statuses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "145836"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_statuses[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "{'compound': -0.866, 'neg': 0.512, 'neu': 0.339, 'pos': 0.149}"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k=pd.DataFrame(all_statuses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "Index([u'compound', u'neg', u'neu', u'pos'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k.pos.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x122e31d0>"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k.neg.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x12e27908>"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k.neu.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x10e2ad30>"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k.compound.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'function' object has no attribute 'hist'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-72-547493a918e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'hist'"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k['compound'].hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x10ea53c8>"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}